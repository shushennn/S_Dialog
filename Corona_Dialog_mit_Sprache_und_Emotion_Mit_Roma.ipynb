{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mein bericht"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "das ist meine abgabe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\n",
    "from eliza import eliza\n",
    "import json\n",
    "import sox\n",
    "from wendel_util import file_update\n",
    "import emorec\n",
    "from google.cloud import speech\n",
    "import io\n",
    "import os, sys\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import pickle\n",
    "import pyttsx3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "file_update()\n",
    "vaccinations = open('vaccinations.json')\n",
    "vaccinations = json.load(vaccinations)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Up To Date\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sr = 16000  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "filename = 'myfile.wav' #recording of my speech"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def record_file():\n",
    "\n",
    "    sr = 44100\n",
    "    duration = 3\n",
    "    data = sd.rec(int(duration * sr), samplerate=sr, channels=1)\n",
    "    sd.wait()  \n",
    "    sf.write(filename, data, sr)\n",
    "    print(data)\n",
    "    \n",
    "    # Convert `data` to 16 bit integers:\n",
    "    y = (np.iinfo(np.int16).max * (data/np.abs(data).max())).astype(np.int16) \n",
    "    \n",
    "    write(filename, sr, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def init_google():\n",
    "    credentials='/Users/shushanamanakhimova/S_Dialog/true-sprite-320717-fbd9b9414a32.json'\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=credentials"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "init_google()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def normalize(in_s):\n",
    "    # e.g. remove stopwords, lemmatization, stemming, \n",
    "    return in_s.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def transcribe(): #transcribing my speech into text\n",
    "    client = speech.SpeechClient()\n",
    "    with io.open(filename, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    audio = speech.RecognitionAudio(content = content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code=\"de-DE\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    for result in response.results:\n",
    "        for index, alternative in enumerate(result.alternatives):\n",
    "            print(\"Transcript {}: {}\".format(index, alternative.transcript))\n",
    "            return alternative.transcript"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def speech_input():\n",
    "    record_file()\n",
    "    text = transcribe()\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    " def do_input():\n",
    "    return speech_input()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "phrases = {'hello':'Willkommen bei der Corona Impfauskunft. Fragen Sie!', \n",
    "    'continue':'Weiter!', \n",
    "    'goodbye':'Vielen Dank für Ihren Besuch!', \n",
    "    'done':'fertig', \n",
    "    'done':'tschüss'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "states_d = {'schleswig':'SH', 'hamburg':'HH', 'berlin':'BE', 'bayern':'BY', \n",
    "            'niedersachsen': 'NI', 'bremen': 'HB', \n",
    "            'nordrhein':'NW', 'hessen':'HE', 'rheinland':'RP', 'baden':'BW', \n",
    "            'saarland': 'SL', 'brandenburg':'BB', 'mecklenburg':'MV', 'sachsen':'SN',\n",
    "            'anhalt':'ST', 'thüringen':'TH', 'deutschland':'DE', 'hier':'DE'}\n",
    "state_names = {'SH':'Schleswig-Hostein', 'HH':'Hamburg', 'BE':'Berlin', 'BY':'Bayern', \n",
    "            'NI':'Niedersachsen', 'HB':'Bremen', \n",
    "            'NW': 'Nordrhein Westphalen', 'HE':'Hessen', 'RP':'Rheinland Pfalz', 'BW':'Baden Würthenberg', \n",
    "            'SL':'Saarland', 'BB':'Brandenburg', 'MV':'Mecklenburg Vorpommern', \n",
    "            'SN': 'Sachsen', 'ST':'Sachsen-Anhalt', 'TH':'Thüringen', 'DE':'Deutschland'}\n",
    "vaccines_d = {'biontech':'biontech', 'biontec':'biontech', \n",
    "              'moderna':'moderna', \n",
    "              'janssen':'janssen', 'jansen':'janssen',\n",
    "              'delta':'delta',\n",
    "              'astraZeneca':'astraZeneca', 'astra':'astraZeneca', 'zeneca':'astraZeneca'}\n",
    "vaccine_names = {'biontech':'Biontech', 'moderna':'Moderna', 'janssen':'Janssen', 'delta':'Delta',\n",
    "              'astraZeneca':'Astra Zeneca'}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def semantic(input_s):\n",
    "    semantics = {'state':'', 'vaccine':'', 'answer':0}\n",
    "    for key in states_d.keys():\n",
    "        if key in input_s:\n",
    "            semantics['state'] = states_d[key]\n",
    "            break\n",
    "    for key in vaccines_d.keys():\n",
    "        if key in input_s:\n",
    "            semantics['vaccine'] = vaccines_d[key]\n",
    "            break\n",
    "    return semantics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# expects semantics: semantics[0] == bundesland, semantics[1] == impfstoff \n",
    "def data(semantics):\n",
    "    s = semantics['state']\n",
    "    v = semantics['vaccine']\n",
    "    if s: # state given\n",
    "        if s != 'DE':\n",
    "            if v: # and vaccine given\n",
    "                semantics['answer'] = vaccinations[\"data\"][\"states\"][s]['vaccination'][v]\n",
    "            else: # all vaccines for state\n",
    "                semantics['answer'] = vaccinations[\"data\"][\"states\"][s]['vaccinated']\n",
    "        else:\n",
    "            if v: # and vaccine given\n",
    "                semantics['answer'] = vaccinations[\"data\"]['vaccination'][v]\n",
    "            else: # all vaccines for Germany\n",
    "                semantics['answer'] = vaccinations['data']['vaccinated']\n",
    "    else: # no state\n",
    "        if v: # but vaccine\n",
    "            semantics['answer'] = vaccinations[\"data\"]['vaccination'][v]\n",
    "        else: # nothing given\n",
    "            semantics['answer'] = None\n",
    "    return semantics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def init_eliza():\n",
    "    root = r'/Users/shushanamanakhimova/S_Dialog/'\n",
    "    elz = eliza.Eliza()\n",
    "    elz.load(root+'eliza/deutsch.txt')\n",
    "    return elz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def output(semantics, inputs):\n",
    "    ret = ''\n",
    "    s = semantics['state']\n",
    "    v = semantics['vaccine']\n",
    "    a = semantics['answer']\n",
    "    if s: # state given\n",
    "        s = util.state_names[s]\n",
    "        if v: # and vaccine given\n",
    "            v = util.vaccine_names[v]\n",
    "            ret = 'Die Impfungen für {} mit {} sind {}'.format(s, v, a)\n",
    "        else: # all vaccines for state\n",
    "            ret = 'Die Impfungen für {} sind {}'.format(s, a)\n",
    "    else: # no state\n",
    "        if v: # but vaccine\n",
    "            v = util.vaccine_names[v]\n",
    "            ret = 'Die Impfungen in Deutschland mit {} sind {}'.format(v, a)\n",
    "        else: # nothing given\n",
    "            ret =  elz.respond(inputs)\n",
    "    return ret"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tts(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('voice', 'german')\n",
    "    engine.setProperty('rate', 200)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def output_s(text):\n",
    "    print('output: '+text)\n",
    "    tts(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "emo_dict = {'happiness':'freundlich', 'neutral': 'wie immer', 'anger': 'ärgerlich', 'sadness': 'traurig', \n",
    "            'fear': 'ängstlich', 'boredom':'gelangweilt', 'disgust':'angeekelt'}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "elz = init_eliza()\n",
    "emoRec = emorec.EmoRec()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def dialogmanager(elz):\n",
    "    output_s(phrases['hello'])\n",
    "    input_s = do_input()\n",
    "    input_s = normalize(input_s)\n",
    "    while input_s and input_s != phrases['done']:\n",
    "        emotion = emeoRec.classify(filename)[0]\n",
    "        emotion_g = emo_dict[emotion]\n",
    "        output_s('ich merke du bist '+emotion_g)\n",
    "        semantics = semantic(input_s)\n",
    "        semantics = data(semantics)\n",
    "        out_string = output(semantics, input_s)\n",
    "        output_s(out_string)\n",
    "        input_s = do_input()\n",
    "\n",
    "        if (input_s):\n",
    "            input_s = normalize(input_s)\n",
    "        else:\n",
    "            \n",
    "            output_s(phrases['goodbye'])\n",
    "     output_s(phrases['goodbye'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "dialogmanager()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extracting features...\n",
      "training a model...\n",
      "done\n",
      "output: Frag was!\n",
      "[[-2.0200850e-05]\n",
      " [ 8.3172981e-06]\n",
      " [-8.6314911e-05]\n",
      " ...\n",
      " [ 4.3349137e-05]\n",
      " [-3.7719739e-05]\n",
      " [-3.0712995e-06]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c7e188b53349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0melz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_eliza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0memoRec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memorec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmoRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdialogmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-2b0921ea10c7>\u001b[0m in \u001b[0;36mdialogmanager\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moutput_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Frag was!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0minput_s\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_s\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'fertig'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memoRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-02825e91f731>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(in_s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# e.g. remove stopwords, lemmatization, stemming,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0min_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c0a83c770cf16fd91fc106a55dfaa45dfea28f1fe4b971d1d264322b3792468"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}